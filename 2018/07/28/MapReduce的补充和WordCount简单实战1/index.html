<!DOCTYPE html>
<html lang="zh-Hans">

<head>

  <!-- Minima -->
  <!-- Hexo theme created by @adisaktijrs -->

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">

  
  <title>MapReduce的补充和WordCount简单实战(一)</title>
  
  <link rel="canonical" href="http://homxuwang.github.io/2018/07/28/MapReduce%E7%9A%84%E8%A1%A5%E5%85%85%E5%92%8CWordCount%E7%AE%80%E5%8D%95%E5%AE%9E%E6%88%981/">
  
  <meta name="description" content="官网介绍：http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html 首先回顾一些MapReduce的基础知识：https://ho">
  
  
  <meta name="author" content="homxuwang">
  
  
  
  <meta property="og:site_name" content="Homxu" />
  <meta property="og:type" content="article" />
  <meta property="og:title" content="MapReduce的补充和WordCount简单实战(一)" />
  
  <meta property="og:description" content="官网介绍：http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html 首先回顾一些MapReduce的基础知识：https://ho">
  
  <meta property="og:url" content="http://homxuwang.github.io/2018/07/28/MapReduce%E7%9A%84%E8%A1%A5%E5%85%85%E5%92%8CWordCount%E7%AE%80%E5%8D%95%E5%AE%9E%E6%88%981/" />

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="MapReduce的补充和WordCount简单实战(一)">
  
  <meta name="twitter:description" content="官网介绍：http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html 首先回顾一些MapReduce的基础知识：https://ho">
  
  
  
  
  <meta name="twitter:url" content="http://homxuwang.github.io/2018/07/28/MapReduce%E7%9A%84%E8%A1%A5%E5%85%85%E5%92%8CWordCount%E7%AE%80%E5%8D%95%E5%AE%9E%E6%88%981/" />

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Preload fonts
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="preload" href="/fonts/dm-serif-display-v4-latin-regular.woff2" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="/fonts/inter-v2-latin-regular.woff2" as="font" type="font/woff2" crossorigin>

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  
<link rel="stylesheet" href="/css/normalize.css">

  
<link rel="stylesheet" href="/css/skeleton.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
<link rel="stylesheet" href="/css/prism-dark.css">

  
<link rel="stylesheet" href="/css/prism-line-numbers.css">

  <!-- User css -->
  
  
<link rel="stylesheet" href="/css/user.css">

  

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="/images/favicon.png">

  <!-- Custom Theme Color Style
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <style>
  a:not(.icon) {
    text-decoration-color: #0FA0CE;
    background-image: linear-gradient(
      to bottom,
      rgba(0, 0, 0, 0) 50%,
      #0FA0CE 50%
    );
  }
  blockquote {
    border-left: 8px solid #0FA0CE;
  }
  .nanobar .bar {
    background: #0FA0CE;
  }
  .button.button-primary:hover,
  button.button-primary:hover,
  input[type="submit"].button-primary:hover,
  input[type="reset"].button-primary:hover,
  input[type="button"].button-primary:hover,
  .button.button-primary:focus,
  button.button-primary:focus,
  input[type="submit"].button-primary:focus,
  input[type="reset"].button-primary:focus,
  input[type="button"].button-primary:focus {
    background-color: #0FA0CE;
    border-color: #0FA0CE;
  }
  input[type="email"]:focus,
  input[type="number"]:focus,
  input[type="search"]:focus,
  input[type="text"]:focus,
  input[type="tel"]:focus,
  input[type="url"]:focus,
  input[type="password"]:focus,
  textarea:focus,
  select:focus {
    border: 1px solid #0FA0CE;
  }
</style>

  <!-- Google Analytics (With Privacy Settings On)
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  

  
  <script src="/js/pic.min.js" defer></script>
  

  
  <script src="/js/search.min.js" defer></script>
  

<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div class="container">
    <div class="row">
      <div>

        <div class="row">
  <div class="two columns" style="max-width: 50px">
    <h1 class="mt-2 mode">
      <div onclick=setDarkMode(true) id="darkBtn">🌑</div>
      <div onclick=setDarkMode(false) id="lightBtn" class=hidden>☀️</div>
      <script >
        if (localStorage.getItem('preferredTheme') == 'dark') {
          setDarkMode(true)
        }
        function setDarkMode(isDark) {
          var darkBtn = document.getElementById('darkBtn')
          var lightBtn = document.getElementById('lightBtn')
          if (isDark) {
            lightBtn.style.display = "block"
            darkBtn.style.display = "none"
            localStorage.setItem('preferredTheme', 'dark');
          } else {
            lightBtn.style.display = "none"
            darkBtn.style.display = "block"
            localStorage.removeItem('preferredTheme');
          }
          document.body.classList.toggle("darkmode");
        }
      </script>
    </h1>
  </div>

  <div class="six columns ml-1">
    <h1 class="mt-2">
      Hi July.HX
    </h1>
  </div>

  <div class="twelve columns">
    <div class="row">
      <div class="nine columns left">
        <a href="/">Home</a>
        
        
      </div>
    </div>
    <hr style="margin-bottom: 2.6rem">
  </div>
</div>

        <div class="trans">
            <h2>MapReduce的补充和WordCount简单实战(一)</h2>

  <p>官网介绍：<a target="_blank" rel="noopener" href="http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html">http://hadoop.apache.org/docs/current/hadoop-mapreduce-client/hadoop-mapreduce-client-core/MapReduceTutorial.html</a></p>
<p>首先回顾一些MapReduce的基础知识：<br><a href="https://homxuwang.github.io/2018/04/24/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89%E2%80%94%E2%80%94MapReduce/">https://homxuwang.github.io/2018/04/24/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0%EF%BC%88%E5%85%AD%EF%BC%89%E2%80%94%E2%80%94MapReduce/</a></p>
<ul>
<li>Hadoop MapReduce是Google MapReduce的实现</li>
<li>MapReduce的优点： 海量数据离线处理 易开发(JAVA API) 易运行</li>
<li>MapReduce的缺点：<br>  实时流式计算（MR是根据请求服务的方式进行计算；多个应用程序存在依赖关系，MR的作业，数据需要落地到HDFS或者磁盘。所以不能实现实时流式计算）</li>
</ul>
<h1 id="MapReduce的执行过程"><a href="#MapReduce的执行过程" class="headerlink" title="MapReduce的执行过程"></a>MapReduce的执行过程</h1><blockquote>
<p>参考：<a target="_blank" rel="noopener" href="https://www.cnblogs.com/ahu-lichang/p/6645074.html">https://www.cnblogs.com/ahu-lichang/p/6645074.html</a></p>
</blockquote>
<p>官网的介绍：</p>
<blockquote>
<p>A MapReduce job usually splits the input data-set into independent chunks which are processed by the map tasks in a completely parallel manner. The framework sorts the outputs of the maps, which are then input to the reduce tasks. Typically both the input and the output of the job are stored in a file-system. The framework takes care of scheduling tasks, monitoring them and re-executes the failed tasks.</p>
</blockquote>
<p><img src="MapReduce%E7%9A%84%E8%A1%A5%E5%85%85%E5%92%8CWordCount%E7%AE%80%E5%8D%95%E5%AE%9E%E6%88%981/1.png"></p>
<ul>
<li>Input –&gt; Spliting 一个文件被分成很多个块（默认情况下一个split对应HDFS中的一个block，用户可以进行修改）</li>
<li>Spliting –&gt; Mapping 一个块交由一个Map任务处理，处理完的结果写到本地</li>
<li>Mapping –&gt; Shuffling –&gt; Reducing写到本地的文件通过Shuffle后进行传输，把相同的key写到一个Reduce中,在Reduce中进行统计</li>
<li>Reducing统计的结果最终写到文件系统上</li>
</ul>
<p>看看官网的解释：</p>
<blockquote>
<p>The MapReduce framework operates exclusively on &lt;key, value&gt; pairs, that is, the framework views the input to the job as a set of &lt;key, value&gt; pairs and produces a set of &lt;key, value&gt; pairs as the output of the job, conceivably of different types.</p>
<p>The key and value classes have to be serializable by the framework and hence need to implement the Writable interface. Additionally, the key classes have to implement the WritableComparable interface to facilitate sorting by the framework.</p>
<p>Input and Output types of a MapReduce job:</p>
<p>(input) &lt;k1, v1&gt; -&gt; map -&gt; &lt;k2, v2&gt; -&gt; combine -&gt; &lt;k2, v2&gt; -&gt; reduce -&gt; &lt;k3, v3&gt; (output)</p>
</blockquote>
<h2 id="关于Writable接口"><a href="#关于Writable接口" class="headerlink" title="关于Writable接口"></a>关于Writable接口</h2><p>在上面的介绍中看到，key和value需要实现<code>Writable</code>接口，并且key还需要实现<code>WritableComparable</code>接口</p>
<p>这个接口需要反复阅读</p>
<p>关于<code>Writable</code>接口的介绍：<a target="_blank" rel="noopener" href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/io/Writable.html">http://hadoop.apache.org/docs/current/api/org/apache/hadoop/io/Writable.html</a></p>
<p>关于<code>WritableComparable</code>接口的介绍：<br><a target="_blank" rel="noopener" href="http://hadoop.apache.org/docs/current/api/org/apache/hadoop/io/WritableComparable.html">http://hadoop.apache.org/docs/current/api/org/apache/hadoop/io/WritableComparable.html</a></p>
<p>在<code>Writable</code>接口中主要实现<code>write</code>和<code>readFields</code>方法。</p>
<p>再看上文面的wordcount的图和<code>(input) &lt;k1, v1&gt; -&gt; map -&gt; &lt;k2, v2&gt; -&gt; combine -&gt; &lt;k2, v2&gt; -&gt; reduce -&gt; &lt;k3, v3&gt; (output)</code>这个过程：</p>
<p>其中<code>k1</code>就是<code>偏移量</code>。第一行的第一个字符从0开始，<code>v1</code>就是这一行的数据<code>Deer Bear River</code>。那么第二行的偏移量就是第一行的字符的长度相加，值就是<code>Car Car River</code>。以此类推</p>
<p>经过一层转换<code>k2</code>就是上面每一行的单词,每个单词相当于是从<code>v1</code>中拆分出来(Split(“ “))，是一个<code>Text</code>类型，每个单词就是一个1。<code>v2</code>就是一个<code>IntWritable</code>或<code> LongWritable</code>类型。</p>
<p>reduce输出的就是每个单词输出的总和。<code>k3</code>就是每个单词，<code>v3</code>就是单词出现的总和。</p>
<h2 id="JAVA-API的简单介绍"><a href="#JAVA-API的简单介绍" class="headerlink" title="JAVA API的简单介绍"></a>JAVA API的简单介绍</h2><p><img src="MapReduce%E7%9A%84%E8%A1%A5%E5%85%85%E5%92%8CWordCount%E7%AE%80%E5%8D%95%E5%AE%9E%E6%88%981/3_1.png"></p>
<ol>
<li>看上图，首先读取文件使用<code>InputFormat</code>类，它是一个接口，在源码中描述为<blockquote>
<p><code>InputFormat</code> describes the input-specification for a  Map-Reduce job.<br><img src="MapReduce%E7%9A%84%E8%A1%A5%E5%85%85%E5%92%8CWordCount%E7%AE%80%E5%8D%95%E5%AE%9E%E6%88%981/3.png" alt="InputFormat的实现类"></p>
</blockquote>
</li>
<li><code>InputFormat</code>的实现类中，用的比较多的是<code>FileInputFormat</code>类.这是一个读取文件系统的基本的类.但是<code>FileInputFormat</code>类仍然是个抽象类。<br>那么继续找它的子类<br><img src="MapReduce%E7%9A%84%E8%A1%A5%E5%85%85%E5%92%8CWordCount%E7%AE%80%E5%8D%95%E5%AE%9E%E6%88%981/4.png" alt="FileInputFormat的实现类"><br>可以看到<code>TextInputFormat</code>类.这时候它就是一个实现的类了</li>
</ol>
<p><img src="MapReduce%E7%9A%84%E8%A1%A5%E5%85%85%E5%92%8CWordCount%E7%AE%80%E5%8D%95%E5%AE%9E%E6%88%981/5.png" alt="TextInputFormat类"></p>
<p>官方文档的介绍：</p>
<blockquote>
<p>An {@link InputFormat} for plain text files.  Files are broken into lines.<br> Either linefeed or carriage-return are used to signal end of line.  Keys are<br> the position in the file, and values are the line of text.. </p>
</blockquote>
<p>其中<code>InputFormat</code>中有几个关键的方法：</p>
<ol>
<li><code>InputSplit[] getSplits(JobConf job, int numSplits) throws IOException;</code><br>即将一个输入文件分成很多Split，每一个Split交给一个MapTask处理的方法。它的返回值是一个数组，可见一个输入文件可能会的到好几个<code>InputSplit</code></li>
</ol>
<p><img src="MapReduce%E7%9A%84%E8%A1%A5%E5%85%85%E5%92%8CWordCount%E7%AE%80%E5%8D%95%E5%AE%9E%E6%88%981/6.png" alt="getSplits方法"></p>
<ol start="2">
<li><code>RecordReader&lt;K, V&gt; getRecordReader(InputSplit split,JobConf job,Reporter reporter) throws IOException;</code><br>它是一个记录读取的方法，从参数可以看到，它从<code>InputSplit[]</code>数组中读进数据，可以知道每一行的数据是什么。</li>
</ol>
<p><img src="MapReduce%E7%9A%84%E8%A1%A5%E5%85%85%E5%92%8CWordCount%E7%AE%80%E5%8D%95%E5%AE%9E%E6%88%981/7.png" alt="getRecordReader方法"></p>
<p>在<code>InputFormat</code>读进数据后(对于文本就是使用<code>TextInputFormat</code>），从图中可以看出，被拆分成好多个<code>Split</code>。拿到<code>Split</code>后，使用RR(RecordReader)把每个<code>Split</code>中的数据读取出来,一行一行的读，每读一行，交由一个<code>map</code>处理.<code>Partitioner</code>将相同的<code>key</code>交到同一个<code>Reduce</code>上，从图中可以看出，<code>key</code>可能会被发送到node1或者node2.中间有一个<code>shuffle</code>的过程，结果交由<code>reduce</code>处理。处理完的结果交给<code>OutputFormat</code>。</p>
<ol start="3">
<li><code>OutputFormat</code></li>
</ol>
<blockquote>
<p><code>OutputFormat</code> describes the output-specification for a  Map-Reduce job.</p>
</blockquote>
<p><img src="MapReduce%E7%9A%84%E8%A1%A5%E5%85%85%E5%92%8CWordCount%E7%AE%80%E5%8D%95%E5%AE%9E%E6%88%981/8.png" alt="OutputFormat的方法"></p>
<p>其中<code>getRecordWriter</code>方法就对应<code>InputFormat</code>的<code>getRecordReader</code>方法</p>
<p>继续寻找它的实现类-&gt;<code>FileOutputFormat</code>-&gt;<code>TextOutputFormat</code></p>
<blockquote>
<p>An {@link OutputFormat} that writes plain text files.<br>将数据以文本的方式写出去</p>
</blockquote>
<h2 id="几个核心概念"><a href="#几个核心概念" class="headerlink" title="几个核心概念"></a>几个核心概念</h2><ul>
<li><p><code>Split</code><br>  Split是交由MapReduce作业来处理的数据块，是MapReduce中最小的计算单元<br>  HDFS：blocksize是HDFS中最小的存储单元 128M（或者自己设定）<br>  默认情况下：它们两个一一对应（也可以手动设置）</p>
</li>
<li><p><code>InputFormat</code><br>InputFormat将输入数据进行分片(split)：<code>InputSplit[] getSplits(JobConf job, int numSplits) throws IOException</code><br>默认实用比较多的是<code>TextInputFormat</code>,处理文本格式的数据</p>
</li>
<li><p><code>OutputFormat</code><br>  和InputFormat对应</p>
</li>
<li><p><code>Combiner</code></p>
</li>
<li><p><code>Partitioner</code></p>
</li>
</ul>
<p>在通过一张图对以上内容进行梳理：<br><img src="MapReduce%E7%9A%84%E8%A1%A5%E5%85%85%E5%92%8CWordCount%E7%AE%80%E5%8D%95%E5%AE%9E%E6%88%981/9.png" alt="Mapreduce原理"></p>
<h1 id="MapReduce架构"><a href="#MapReduce架构" class="headerlink" title="MapReduce架构"></a>MapReduce架构</h1><h2 id="MapReduce1-x架构"><a href="#MapReduce1-x架构" class="headerlink" title="MapReduce1.x架构"></a>MapReduce1.x架构</h2><p><img src="MapReduce%E7%9A%84%E8%A1%A5%E5%85%85%E5%92%8CWordCount%E7%AE%80%E5%8D%95%E5%AE%9E%E6%88%981/10.png" alt="MapReduce1.x架构"></p>
<ol>
<li>JobTracker:JT<br> 作业的管理者<br> 将作业分解成一堆任务：Task（包括MapTask和ReduceTask)<br> 将任务分派给TaskTracker运行<br> 作业的监控、容错处理（task作业挂了，重启task）<br> 在一定时间间隔内，JT没有收到TT的心跳信息,则将任务分配到其他TT上执行</li>
<li>TaskTracker：TT<br> 任务的执行者<br> 在TT上执行Task（MapTask和ReduceTask）<br> 会与JT进行交互：执行/启动/停止作业，发送心跳信息给JT</li>
<li>MapTask<br> 自己开发的map任务交由该Task来处理<br> 解析每条记录的数据，交给自己的map方法处理<br> 将map的输出结果写到本地磁盘（有些作业只有Map，则写到HDFS）<br>4） ReduceTadk<br> 将MapTask输出的数据进行读取<br> 按照数据进行分组传给自己编写的reduce方法处理<br> 处理结果输出</li>
</ol>
<h2 id="MapReduce2-x架构"><a href="#MapReduce2-x架构" class="headerlink" title="MapReduce2.x架构"></a>MapReduce2.x架构</h2><p><img src="MapReduce%E7%9A%84%E8%A1%A5%E5%85%85%E5%92%8CWordCount%E7%AE%80%E5%8D%95%E5%AE%9E%E6%88%981/1.jpeg" alt="MapReduce2.x架构"></p>
<p>和yarn中的流程类似,MapReduce可以在YARN上跑。</p>
<p>下一篇实战。</p>

  <p><a class="classtest-link" href="/tags/hadoop/" rel="tag">hadoop</a>, <a class="classtest-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a> — Jul 28, 2018</p>
  


        </div>
        <div class="row mt-2">
  <h3>Search</h3>
  <div><input id="search-text" title="search" class="search-text" type="text" placeholder="search......"></div>
  <div style="margin-top: 1.5rem;">
    <ul id="result"></ul>
  </div>
</div>
        <div class="row mt-2">
  
    <div class="eight columns">
      <p id="madewith">Made with ❤ and
        <a class="footer-link icon" href="https://hexo.io" target="_blank" style="text-decoration: none;" rel="noreferrer" aria-label="Hexo.io">
        <svg class="hexo svg-hov" width="14" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><title>Hexo.js</title><path d="M12 .007L1.57 6.056V18.05L12 23.995l10.43-6.049V5.952L12 .007zm4.798 17.105l-.939.521-.939-.521V12.94H9.08v4.172l-.94.521-.938-.521V6.89l.939-.521.939.521v4.172h5.84V6.89l.94-.521.938.521v10.222z"/></svg>
        </a>
        
        at <a href="https://en.wikipedia.org/wiki/Earth" target="_blank" rel="noreferrer">Earth</a>.</p>
        
    </div>

    <!-- Sepcial thanks to https://simpleicons.org/ for the icons -->
    <div class="four columns mb-3 posisi" >
      
      <a class="ml-0 footer-link icon" href="https://github.com/homxuwang" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="GitHub">
        <svg class="github svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
      </a>
      

      

      

      

      

    </div>
  
</div>

      </div>

    </div>

  </div>
  <script src="/js/nanobar.min.js"></script>

  <script>
    var options = {
      classname: 'nanobar',
      id: 'myNanobar'
    };
    var nanobar = new Nanobar(options);
    nanobar.go(30);
    nanobar.go(76);
    nanobar.go(100);
  </script>

</body>

</html>