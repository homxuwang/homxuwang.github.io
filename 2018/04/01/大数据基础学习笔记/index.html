<!DOCTYPE html>
<html lang="zh-Hans">

<head>

  <!-- Minima -->
  <!-- Hexo theme created by @adisaktijrs -->

  <!-- Basic Page Needs
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta charset="utf-8">

  
  <title>大数据基础学习笔记（一）——Hadoop相关知识</title>
  
  <link rel="canonical" href="http://homxuwang.github.io/2018/04/01/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">
  
  <meta name="description" content="HadoopHadoop的应用现状和构成简介下图为Hadoop在企业中的 应用架构  访问层不用多说，满足企业的数据分析、数据挖掘和数据实时查询功能。为了满足访问层的需求，大数据层的各个技术对其进行支撑。（1）离线分析：大量数据拿过来之后进行批量处理。其中MR是MapReduce的简称，Hive数据">
  
  
  <meta name="author" content="homxuwang">
  
  
  
  <meta property="og:site_name" content="Homxu" />
  <meta property="og:type" content="article" />
  <meta property="og:title" content="大数据基础学习笔记（一）——Hadoop相关知识" />
  
  <meta property="og:description" content="HadoopHadoop的应用现状和构成简介下图为Hadoop在企业中的 应用架构  访问层不用多说，满足企业的数据分析、数据挖掘和数据实时查询功能。为了满足访问层的需求，大数据层的各个技术对其进行支撑。（1）离线分析：大量数据拿过来之后进行批量处理。其中MR是MapReduce的简称，Hive数据">
  
  <meta property="og:url" content="http://homxuwang.github.io/2018/04/01/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" />

  <meta name="twitter:card" content="summary_large_image">
  <meta name="twitter:title" content="大数据基础学习笔记（一）——Hadoop相关知识">
  
  <meta name="twitter:description" content="HadoopHadoop的应用现状和构成简介下图为Hadoop在企业中的 应用架构  访问层不用多说，满足企业的数据分析、数据挖掘和数据实时查询功能。为了满足访问层的需求，大数据层的各个技术对其进行支撑。（1）离线分析：大量数据拿过来之后进行批量处理。其中MR是MapReduce的简称，Hive数据">
  
  
  
  
  <meta name="twitter:url" content="http://homxuwang.github.io/2018/04/01/%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/" />

  <!-- Mobile Specific Metas
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <meta name="viewport" content="width=device-width, initial-scale=1">

  <!-- Preload fonts
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="preload" href="/fonts/dm-serif-display-v4-latin-regular.woff2" as="font" type="font/woff2" crossorigin>
  <link rel="preload" href="/fonts/inter-v2-latin-regular.woff2" as="font" type="font/woff2" crossorigin>

  <!-- CSS
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  
<link rel="stylesheet" href="/css/normalize.css">

  
<link rel="stylesheet" href="/css/skeleton.css">

  
<link rel="stylesheet" href="/css/custom.css">

  
<link rel="stylesheet" href="/css/prism-dark.css">

  
<link rel="stylesheet" href="/css/prism-line-numbers.css">

  <!-- User css -->
  
  
<link rel="stylesheet" href="/css/user.css">

  

  <!-- Favicon
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <link rel="icon" type="image/png" href="/images/favicon.png">

  <!-- Custom Theme Color Style
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  <style>
  a:not(.icon) {
    text-decoration-color: #0FA0CE;
    background-image: linear-gradient(
      to bottom,
      rgba(0, 0, 0, 0) 50%,
      #0FA0CE 50%
    );
  }
  blockquote {
    border-left: 8px solid #0FA0CE;
  }
  .nanobar .bar {
    background: #0FA0CE;
  }
  .button.button-primary:hover,
  button.button-primary:hover,
  input[type="submit"].button-primary:hover,
  input[type="reset"].button-primary:hover,
  input[type="button"].button-primary:hover,
  .button.button-primary:focus,
  button.button-primary:focus,
  input[type="submit"].button-primary:focus,
  input[type="reset"].button-primary:focus,
  input[type="button"].button-primary:focus {
    background-color: #0FA0CE;
    border-color: #0FA0CE;
  }
  input[type="email"]:focus,
  input[type="number"]:focus,
  input[type="search"]:focus,
  input[type="text"]:focus,
  input[type="tel"]:focus,
  input[type="url"]:focus,
  input[type="password"]:focus,
  textarea:focus,
  select:focus {
    border: 1px solid #0FA0CE;
  }
</style>

  <!-- Google Analytics (With Privacy Settings On)
  –––––––––––––––––––––––––––––––––––––––––––––––––– -->
  

  
  <script src="/js/pic.min.js" defer></script>
  

  
  <script src="/js/search.min.js" defer></script>
  

<meta name="generator" content="Hexo 5.4.0"></head>

<body>
  <div class="container">
    <div class="row">
      <div>

        <div class="row">
  <div class="two columns" style="max-width: 50px">
    <h1 class="mt-2 mode">
      <div onclick=setDarkMode(true) id="darkBtn">🌑</div>
      <div onclick=setDarkMode(false) id="lightBtn" class=hidden>☀️</div>
      <script >
        if (localStorage.getItem('preferredTheme') == 'dark') {
          setDarkMode(true)
        }
        function setDarkMode(isDark) {
          var darkBtn = document.getElementById('darkBtn')
          var lightBtn = document.getElementById('lightBtn')
          if (isDark) {
            lightBtn.style.display = "block"
            darkBtn.style.display = "none"
            localStorage.setItem('preferredTheme', 'dark');
          } else {
            lightBtn.style.display = "none"
            darkBtn.style.display = "block"
            localStorage.removeItem('preferredTheme');
          }
          document.body.classList.toggle("darkmode");
        }
      </script>
    </h1>
  </div>

  <div class="six columns ml-1">
    <h1 class="mt-2">
      Hi July.HX
    </h1>
  </div>

  <div class="twelve columns">
    <div class="row">
      <div class="nine columns left">
        <a href="/">Home</a>
        
        
      </div>
    </div>
    <hr style="margin-bottom: 2.6rem">
  </div>
</div>

        <div class="trans">
            <h2>大数据基础学习笔记（一）——Hadoop相关知识</h2>

  <h1 id="Hadoop"><a href="#Hadoop" class="headerlink" title="Hadoop"></a>Hadoop</h1><h2 id="Hadoop的应用现状和构成简介"><a href="#Hadoop的应用现状和构成简介" class="headerlink" title="Hadoop的应用现状和构成简介"></a>Hadoop的应用现状和构成简介</h2><p>下图为Hadoop在企业中的 应用架构</p>
<p><img src="%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/1.png" alt="Hadoop在企业中的应用架构"></p>
<p>访问层不用多说，满足企业的数据分析、数据挖掘和数据实时查询功能。<br>为了满足访问层的需求，大数据层的各个技术对其进行支撑。<br>（1）离线分析：大量数据拿过来之后进行批量处理。其中MR是MapReduce的简称，Hive数据仓库和Pig也可以进行离线数据分析。<br>（2）实时查询：其中Hbase是一个可以支持几十亿行数据的非常好的分布式数据库。<br>（3）BI分析：Mahout是Hadoop平台上的一款数据挖掘应用。可以把各种数据挖掘，机器学习和商务智能的算法用MapReduce实现。否则开发人员要自己用MapReduce写决策树算法。</p>
<p>下图为一些大数据计算模式及其代表产品</p>
<p><img src="%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/2.png" alt="大数据计算模式及其代表产品"></p>
<p>下图为Hadoop项目结构</p>
<p><img src="%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/3.png" alt="Hadoop项目结构"></p>
<p>YARNz专门负责调度内存，CPU，带宽等计算资源。而上面的事完成具体的计算工作的。</p>
<p>Tez会把很多的MapReduce作业进行分析优化，构建成一个有向无环图，保证获得最好的处理效率。</p>
<p>Spark与MapReduce类似，也是进行相应的计算。但是Spark是基于内存的，而MapReduce是基于磁盘的计算。MR在计算时，先把数据写到磁盘中，然后c处理结束后再写到分布式文件系统中。所以Spark的性能要高。</p>
<p>Pig实现流数据处理，较MR属于轻量级。它也支持类似于SQL的语句。是一种轻量级的脚本语言。</p>
<p>Oozie是一个工作流管理系统，可以把一个工作分成不同的工作环节。</p>
<p>Zookeeper提供分布式协调一致性服务。</p>
<p>Hbase是一个非关系型数据库，可以支持随机读写。</p>
<p>Flume是专门负责日志收集的，分析一些实时生成的数据流。</p>
<p>Sqoopy用于在Hadoop与传统数据库之间进行数据传递（导入导出等）。可以把之前存到关系型数据库（如Oracle）中的数据导入到HDFS、Hive或者Hbase中，反之亦可。</p>
<p>Ambari是一个安装部署工具，可以在一个集群上面智能化的管理一整套Hadoop上的各个套件。</p>
<p>Hadoop各组件的功能如下：</p>
<p><img src="%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/4.png" alt="Hadoop组件及功能"></p>
<h2 id="Hadoop集群的节点类型"><a href="#Hadoop集群的节点类型" class="headerlink" title="Hadoop集群的节点类型"></a>Hadoop集群的节点类型</h2><p>Hadoop框架中最核心的设计是为海量数据提供存储的<code>HDFS</code>和对数据进行计算的<code>MapReduce</code></p>
<p>MapReduce的作业主要包括：<br>（1）从磁盘或从网络读取数据，即IO密集工作；<br>（2）计算数据，即CPU密集工作</p>
<p>•Hadoop集群的整体性能取决于CPU、内存、网络以及存储之间的性能平衡。因此运营团队在选择机器配置时要针对不同的工作节点选择合适硬件类型<br>•一个基本的Hadoop集群中的节点主要有:</p>
<p>•NameNode：负责协调集群中的数据存储</p>
<p>•DataNode：存储被拆分的数据块</p>
<p>•JobTracker：协调数据计算任务</p>
<p>•TaskTracker：负责执行由JobTracker指派的任务</p>
<p>•SecondaryNameNode：帮助NameNode收集文件系统运行的状态信息</p>
<h1 id="HDFS"><a href="#HDFS" class="headerlink" title="HDFS"></a>HDFS</h1><p>全称：Hadoop Distributed File System.解决海量数据的分布式存储问题。</p>
<h2 id="分布式文件系统的结构"><a href="#分布式文件系统的结构" class="headerlink" title="分布式文件系统的结构"></a>分布式文件系统的结构</h2><p>分布式文件系统在物理结构上是由计算机集群中的多个节点构成的，这些节点分为两类，一类叫“主节点”(Master Node)或者也被称为“名称结点”(NameNode)，另一类叫“从节点”（Slave Node）或者也被称为“数据节点”(DataNode)</p>
<p><img src="%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/5.png" alt="大规模文件系统的整体结构"></p>
<p>HDFS的三个节点：Namenode，Datanode，Secondary Namenode</p>
<p>Namenode：HDFS的守护进程，用来管理文件系统的命名空间，负责记录文件是如何分割成数据块，以及这些数据块分别被存储到那些数据节点上，它的主要功能是对内存及IO进行集中管理。</p>
<p>Datanode：文件系统的工作节点，根据需要存储和检索数据块，并且定期向namenode发送他们所存储的块的列表。</p>
<p>Secondary Namenode：辅助后台程序，与NameNode进行通信，以便定期保存HDFS元数据的快照。</p>
<p>HDFS采用了主从（Master/Slave）结构模型，一个HDFS集群包括一个名称节点（<br>NameNode）和若干个数据节点（DataNode）（如图所示）。名称节点作为中心服务器，负责管理文件系统的命名空间及客户端对文件的访问。集群中的数据节点一般是一个节点运行一个数据节点进程，负责处理文件系统客户端的读/写请求，在名称节点的统一调度下进行数据块的创建、删除和复制等操作。每个数据节点的数据实际上是保存在本地Linux文件系统中的。</p>
<p><img src="%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/10.png" alt="HDFS体系结构"><br>HDFS的缺点：</p>
<p>1.不适合低延迟的数据访问<br>2.无法高效存储大量小文件<br>3.不支持多用户写入及任意修改文件</p>
<h3 id="名称节点和数据节点"><a href="#名称节点和数据节点" class="headerlink" title="名称节点和数据节点"></a>名称节点和数据节点</h3><p><img src="%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/7.png" alt="HDFS主要组件的功能"></p>
<p>在HDFS中，名称节点（NameNode）负责管理分布式文件系统的命名空间（Namespace），保存了两个核心的数据结构，即FsImage和EditLog。</p>
<p>•FsImage用于维护文件系统树以及文件树中所有的文件和文件夹的元数据</p>
<p>•操作日志文件EditLog中记录了所有针对文件的创建、删除、重命名等操作</p>
<p>•名称节点记录了每个文件中各个块所在的数据节点的位置信息。</p>
<p><img src="%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/6.png" alt="名称节点的数据结构"></p>
<p>客户端在访问数据时，先通过名称节点，获取元数据信息，从而知道被访问的数据存到哪些数据节点，获得数据块具体存储位置的信息之后，客户端就会到各个机器上去获取它所需要的数据。写入操作类似，客户端先访问名称节点，一个大文件（如1TB,2TB）要怎么写，然后名称节点会告诉它，把文件分成多少块，每个块放到哪个数据节点上。</p>
<p><img src="%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/9.png" alt="局限性"></p>
<h4 id="FsImage-文件"><a href="#FsImage-文件" class="headerlink" title="FsImage 文件"></a>FsImage 文件</h4><p>•FsImage文件包含文件系统中所有目录和文件inode的序列化形式。每个inode是一个文件或目录的元数据的内部表示，并包含此类信息：文件的复制等级、修改和访问时间、访问权限、块大小以及组成文件的块。对于目录，则存储修改时间、权限和配额元数据</p>
<p>•FsImage文件没有记录块存储在哪个数据节点。而是由名称节点把这些映射保留在内存中，当数据节点加入HDFS集群时，数据节点会把自己所包含的块列表告知给名称节点，此后会定期执行这种告知操作，以确保名称节点的块映射是最新的。</p>
<p>在名称节点启动的时候，它会将FsImage文件中的内容加载到内存中，之后再执行<br>EditLog文件中的各项操作，使得内存中的元数据和实际的同步，存在内存中的元数据支持客户端的读操作。</p>
<p>•一旦在内存中成功建立文件系统元数据的映射，则创建一个新的FsImage文件和一个空的EditLog文件</p>
<p>•名称节点起来之后，HDFS中的更新操作会重新写到EditLog文件中，因为FsImage文件一般都很大（GB级别的很常见），如果所有的更新操作都往FsImage文件中添加，这样会导致系统运行的十分缓慢，但是，如果往EditLog文件里面写就不会这样，因为EditLog 要小很多。每次执行写操作之后，且在向客户端发送成功代码之前，edits文件都需要同步更新</p>
<h4 id="第二名称节点"><a href="#第二名称节点" class="headerlink" title="第二名称节点"></a>第二名称节点</h4><p>第二名称节点是HDFS架构中的一个组成部分，它是用来保存名称节点中对HDFS 元<br>数据信息的备份，并减少名称节点重启的时间。SecondaryNameNode一般是单独运行在一台机器上。</p>
<p><img src="%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/8.png"></p>
<p>SecondaryNameNode的工作情况：</p>
<p>（1）SecondaryNameNode会定期和NameNode通信，请求其停止使用EditLog文件，暂时将新的写操作写到一个新的文件edit.new上来，这个操作是瞬间完成，上层写日志的函数完全感觉不到差别；</p>
<p>（2）SecondaryNameNode通过HTTP GET方式从NameNode上获取到FsImage和EditLog文件，并下载到本地的相应目录下；</p>
<p>（3）SecondaryNameNode将下载下来的FsImage载入到内存，然后一条一条地执行EditLog文件中的各项更新操作，使得内存中的FsImage保持最新；这个过程就是EditLog和FsImage文件合并；</p>
<p>（4）SecondaryNameNode执行完（3）操作之后，会通过post方式将新的FsImage文件发送到NameNode节点上；</p>
<p>（5）NameNode将从SecondaryNameNode接收到的新的FsImage替换旧的FsImage文件，同时将edit.new替换EditLog文件，通过这个过程EditLog就变小。</p>
<h4 id="数据节点（DataNode）"><a href="#数据节点（DataNode）" class="headerlink" title="数据节点（DataNode）"></a>数据节点（DataNode）</h4><p>数据节点是分布式文件系统HDFS的工作节点，负责数据的存储和读取，会根据客<br>户端或者是名称节点的调度来进行数据的存储和检索，并且向名称节点定期发送自己所存储的块的列表</p>
<p>•每个数据节点中的数据会被保存在各自节点的本地Linux文件系统中</p>
<h2 id="HDFS存储原理"><a href="#HDFS存储原理" class="headerlink" title="HDFS存储原理"></a>HDFS存储原理</h2><h3 id="冗余数据保存"><a href="#冗余数据保存" class="headerlink" title="冗余数据保存"></a>冗余数据保存</h3><p>作为一个分布式文件系统，为了保证系统的容错性和可用性，HDFS采用了多副<br>本方式对数据进行冗余存储，通常一个数据块的多个副本会被分布到不同的数据节点上，数据块1被分别存放到数据节点A和C上，数据块2被存放在数据节点A和B上。这种多副本方式具有以下几个优点：<br>（1） 加快数据传输速度</p>
<p>（2） 容易检查数据错误</p>
<p>（3） 保证数据可靠性</p>
<p><img src="%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/11.png" alt="HDFS数据块多副本存储"></p>
<h3 id="数据存取策略"><a href="#数据存取策略" class="headerlink" title="数据存取策略"></a>数据存取策略</h3><h4 id="数据存放"><a href="#数据存放" class="headerlink" title="数据存放"></a>数据存放</h4><p>•第一个副本：放置在上传文件的数据节点；如果是集群外提交，则随机挑选一台磁盘不太满、CPU不太忙的节点</p>
<p>•第二个副本：放置在与第一个副本不同的机架的节点上</p>
<p>•第三个副本：与第一个副本相同机架的其他节点上</p>
<p>•更多副本：随机节点</p>
<p><img src="%E5%A4%A7%E6%95%B0%E6%8D%AE%E5%9F%BA%E7%A1%80%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/12.png" alt="Block的副本放置策略"></p>
<h4 id="数据读取"><a href="#数据读取" class="headerlink" title="数据读取"></a>数据读取</h4><p>•HDFS提供了一个API可以确定一个数据节点所属的机架ID，客户端也可以调用API<br>获取自己所属的机架ID</p>
<p>•当客户端读取数据时，从名称节点获得数据块不同副本的存放位置列表，列表中包含了副本所在的数据节点，可以调用API来确定客户端和这些数据节点所属的机架ID，当发现某个数据块副本对应的机架ID和客户端对应的机架ID相同时，就优先选择该副本读取数据，如果没有发现，就随机选择一个副本读取数据</p>
<h3 id="数据错误与恢复"><a href="#数据错误与恢复" class="headerlink" title="数据错误与恢复"></a>数据错误与恢复</h3><p>HDFS具有较高的容错性，可以兼容廉价的硬件，它把硬件出错看作一种常态，<br>而不是异常，并设计了相应的机制检测数据错误和进行自动恢复，主要包括以下几种情形：名称节点出错、数据节点出错和数据出错。</p>
<h4 id="名称节点出错"><a href="#名称节点出错" class="headerlink" title="名称节点出错"></a>名称节点出错</h4><p>名称节点保存了所有的元数据信息，其中，最核心的两大数据结构是FsImage和Editlog，如果这两个文件发生损坏，那么整个HDFS实例将失效。因此，HDFS设<br>置了备份机制，把这些核心文件同步复制到备份服务器SecondaryNameNode上。当名称节点出错时，就可以根据备份服务器SecondaryNameNode中的FsImage和<br>Editlog数据进行恢复。</p>
<h4 id="数据节点出错"><a href="#数据节点出错" class="headerlink" title="数据节点出错"></a>数据节点出错</h4><p>•每个数据节点会定期向名称节点发送“心跳”信息，向名称节点报告自己的状态</p>
<p>•当数据节点发生故障，或者网络发生断网时，名称节点就无法收到来自一些数据节点的心跳信息，这时，这些数据节点就会被标记为“宕机”，节点上面的所有数据都会被标记为“不可读”，名称节点不会再给它们发送任何I/O请求</p>
<p>•这时，有可能出现一种情形，即由于一些数据节点的不可用，会导致一些数据块的副本数量小于冗余因子•名称节点会定期检查这种情况，一旦发现某个数据块的副本数量小于冗余因子，就会启动数据冗余复制，为它生成新的副本</p>
<p>•HDFS和其它分布式文件系统的最大区别就是可以调整冗余数据的位置</p>
<h4 id="数据出错"><a href="#数据出错" class="headerlink" title="数据出错"></a>数据出错</h4><p>•网络传输和磁盘错误等因素，都会造成数据错误</p>
<p>•客户端在读取到数据后，会采用md5和sha1对数据块进行校验，以确定读取到正确的数据</p>
<p>•在文件被创建时，客户端就会对每一个文件块进行信息摘录，并把这些信息写入到同一个路径的隐藏文件里面</p>
<p>•当客户端读取文件的时候，会先读取该信息文件，然后，利用该信息文件对每个读取的数据块进行校验，如果校验出错，客户端就会请求到另外一个数据节点读取该文件块，并且向名称节点报告这个文件块有错误，名称节点会定期检查并且重新复制这个块</p>
<p>本笔记的来源源自林子雨老师的MOOC课程和课件，地址：<a target="_blank" rel="noopener" href="https://www.icourse163.org/course/XMU-1002335004">https://www.icourse163.org/course/XMU-1002335004</a></p>

  <p><a class="classtest-link" href="/tags/%E5%A4%A7%E6%95%B0%E6%8D%AE/" rel="tag">大数据</a> — Apr 1, 2018</p>
  


        </div>
        <div class="row mt-2">
  <h3>Search</h3>
  <div><input id="search-text" title="search" class="search-text" type="text" placeholder="search......"></div>
  <div style="margin-top: 1.5rem;">
    <ul id="result"></ul>
  </div>
</div>
        <div class="row mt-2">
  
    <div class="eight columns">
      <p id="madewith">Made with ❤ and
        <a class="footer-link icon" href="https://hexo.io" target="_blank" style="text-decoration: none;" rel="noreferrer" aria-label="Hexo.io">
        <svg class="hexo svg-hov" width="14" role="img" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 24 24"><title>Hexo.js</title><path d="M12 .007L1.57 6.056V18.05L12 23.995l10.43-6.049V5.952L12 .007zm4.798 17.105l-.939.521-.939-.521V12.94H9.08v4.172l-.94.521-.938-.521V6.89l.939-.521.939.521v4.172h5.84V6.89l.94-.521.938.521v10.222z"/></svg>
        </a>
        
        at <a href="https://en.wikipedia.org/wiki/Earth" target="_blank" rel="noreferrer">Earth</a>.</p>
        
    </div>

    <!-- Sepcial thanks to https://simpleicons.org/ for the icons -->
    <div class="four columns mb-3 posisi" >
      
      <a class="ml-0 footer-link icon" href="https://github.com/homxuwang" target="_blank" style="text-decoration: none" rel="noreferrer" aria-label="GitHub">
        <svg class="github svg-hov" width="18" role="img" viewBox="0 0 24 24" xmlns="http://www.w3.org/2000/svg"><title>GitHub</title><path d="M12 .297c-6.63 0-12 5.373-12 12 0 5.303 3.438 9.8 8.205 11.385.6.113.82-.258.82-.577 0-.285-.01-1.04-.015-2.04-3.338.724-4.042-1.61-4.042-1.61C4.422 18.07 3.633 17.7 3.633 17.7c-1.087-.744.084-.729.084-.729 1.205.084 1.838 1.236 1.838 1.236 1.07 1.835 2.809 1.305 3.495.998.108-.776.417-1.305.76-1.605-2.665-.3-5.466-1.332-5.466-5.93 0-1.31.465-2.38 1.235-3.22-.135-.303-.54-1.523.105-3.176 0 0 1.005-.322 3.3 1.23.96-.267 1.98-.399 3-.405 1.02.006 2.04.138 3 .405 2.28-1.552 3.285-1.23 3.285-1.23.645 1.653.24 2.873.12 3.176.765.84 1.23 1.91 1.23 3.22 0 4.61-2.805 5.625-5.475 5.92.42.36.81 1.096.81 2.22 0 1.606-.015 2.896-.015 3.286 0 .315.21.69.825.57C20.565 22.092 24 17.592 24 12.297c0-6.627-5.373-12-12-12"/></svg>
      </a>
      

      

      

      

      

    </div>
  
</div>

      </div>

    </div>

  </div>
  <script src="/js/nanobar.min.js"></script>

  <script>
    var options = {
      classname: 'nanobar',
      id: 'myNanobar'
    };
    var nanobar = new Nanobar(options);
    nanobar.go(30);
    nanobar.go(76);
    nanobar.go(100);
  </script>

</body>

</html>